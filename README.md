# ğŸ’¬ Chatbot IA GÃ©nÃ©rative avec Recherche Web â€“ Test Technique Juillet 2025

## ğŸ¯ Objectif du projet

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre dâ€™un test technique pour un poste dâ€™**IngÃ©nieur IA GÃ©nÃ©rative**.  
Lâ€™objectif Ã©tait de dÃ©velopper un **chatbot capable dâ€™interroger un LLM** tout en intÃ©grant dynamiquement des **rÃ©sultats de recherche web rÃ©cents**, afin de fournir des rÃ©ponses contextualisÃ©es et Ã  jour.

> âœ… RequÃªte test attendue :
> *â€œQuels sont les derniers dÃ©veloppements en IA gÃ©nÃ©rative annoncÃ©s cette semaine ? Donne-moi 3 exemples concrets avec leurs sources.â€*

Le projet inclut :
- Une API REST backend construite avec **FastAPI**
- Une logique de **recherche web automatique**
- Deux modes de gÃ©nÃ©ration :
  - Un modÃ¨le cloud via **OpenRouter**
  - Un modÃ¨le local via **Hugging Face Transformers**

---

## ğŸ§± Stack technique

| Composant      | Outil utilisÃ©                                       |
|----------------|-----------------------------------------------------|
| **Langage**    | Python 3.10+                                        |
| **Framework API** | FastAPI + Uvicorn                              |
| **Recherche Web** | `duckduckgo_search` (API gratuite DuckDuckGo)  |
| **LLM Cloud**  | `qwen/qwen2.5-vl-32b-instruct:free` (OpenRouter)   |
| **LLM Local**  | `microsoft/phi-2` via HuggingFace Transformers     |
| **Frontend**   | *(Ã  venir)* â€“ prÃ©vu en React                       |

---

## ğŸš€ FonctionnalitÃ©s principales

- ğŸ” **Recherche web dynamique** : intÃ©gration des rÃ©sultats dans les prompts
- ğŸ¤– **Double mode de rÃ©ponse** :
  - `/ask` â†’ via modÃ¨le distant (OpenRouter)
  - `/ask-local` â†’ via modÃ¨le local (Hugging Face)
- ğŸ§  **Prompt enrichi** : les rÃ©sultats web sont injectÃ©s dans la requÃªte du LLM
- ğŸ” **SÃ©curitÃ©** : les clÃ©s API sont stockÃ©es dans un fichier `.env` non versionnÃ©
- ğŸ§ª **Interface Swagger** pour tester facilement lâ€™API

---

## ğŸ§ª Exemple de fonctionnement

RequÃªte envoyÃ©e :
```json
{
  "prompt": "Quels sont les derniers dÃ©veloppements en IA gÃ©nÃ©rative cette semaine ?"
}
```

Processus :
1. Recherche web automatique (DuckDuckGo)
2. RÃ©sumÃ© des 3 meilleurs rÃ©sultats (titre, URL, extrait)
3. Construction dâ€™un **prompt enrichi**
4. Envoi au modÃ¨le (local ou distant)
5. RÃ©ponse gÃ©nÃ©rÃ©e et retournÃ©e Ã  lâ€™utilisateur

---

## ğŸ“‚ Structure du projet

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ openrouter_service.py
â”‚   â”œâ”€â”€ local_model_service.py
â”‚   â””â”€â”€ web_search.py
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
```

---

## âš™ï¸ Installation du projet

### ğŸ§± 1. Cloner le dÃ©pÃ´t
```bash
git clone https://github.com/ton-pseudo/ton-repo.git
cd ton-repo/backend
```

### ğŸ 2. CrÃ©er un environnement virtuel Python
```bash
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate sous Windows
```

### ğŸ“¦ 3. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### ğŸ” 4. Ajouter le fichier `.env`
```env
OPENROUTER_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx
```

---

## â–¶ï¸ Lancement de lâ€™API

```bash
uvicorn app.main:app --reload
```

Swagger : http://127.0.0.1:8000/docs

---

## ğŸ“¤ Endpoints disponibles

### `/ask` â€“ version cloud (OpenRouter)
```json
POST /ask
{
  "prompt": "Quelle est l'utilitÃ© de l'IA gÃ©nÃ©rative dans la mÃ©decine ?"
}
```

### `/ask-local` â€“ version locale (Phi-2)
```json
POST /ask-local
{
  "prompt": "Quels sont les avantages de lâ€™IA en Ã©ducation ?"
}
```

---

## ğŸ” Fonctionnement interne

1. Appel Ã  `search_web(prompt)`
2. RÃ©sultats injectÃ©s dans un prompt enrichi
3. Envoi au modÃ¨le (cloud ou local)
4. RÃ©ponse gÃ©nÃ©rÃ©e Ã  partir des sources web

---

## ğŸ“Œ Exemple de prompt gÃ©nÃ©rÃ©

```
Voici des informations trouvÃ©es en ligne :

[1] OpenAI annonce GPT-5 - https://openai.com/gpt5
OpenAI prÃ©voit de sortir GPT-5 avec une capacitÃ© multimodale amÃ©liorÃ©e...

[2] Google lance Gemini 1.5 - https://blog.google/ai/gemini
Le modÃ¨le Gemini introduit une architecture plus modulaire...

[3] Stability AI sort Stable LM 2 - https://stability.ai/news
StableLM 2 permet un meilleur contrÃ´le gÃ©nÃ©rationnel...

Ã€ partir de ces sources, rÃ©ponds Ã  la question suivante de maniÃ¨re synthÃ©tique et prÃ©cise :
Quels sont les derniers dÃ©veloppements en IA gÃ©nÃ©rative cette semaine ?
```

---

## ğŸ’¡ Bonus techniques inclus

| Ã‰lÃ©ment                            | ImplÃ©mentÃ© |
|------------------------------------|------------|
| IntÃ©gration des rÃ©sultats web      | âœ…         |
| ModÃ¨le cloud via OpenRouter        | âœ…         |
| ModÃ¨le local via Hugging Face      | âœ…         |
| Fonctionnement hors-ligne          | âœ…         |
| Swagger UI                         | âœ…         |
| SÃ©paration `.env` / `.gitignore`  | âœ…         |

---

## ğŸ“š AmÃ©liorations prÃ©vues

- ğŸŒ Frontend React
- â˜ï¸ DÃ©ploiement Azure (Partie 2)
- ğŸ–¼ï¸ IntÃ©gration VLM (Partie 3)

---

## ğŸ‘¤ RÃ©alisÃ© par

**ThÃ©o Labat**  
Test Technique â€“ IngÃ©nieur IA GÃ©nÃ©rative â€“ Juillet 2025

---

## ğŸ“ Remarques

- Aucune clÃ© API nâ€™est versionnÃ©e
- Aucune solution payante nâ€™a Ã©tÃ© utilisÃ©e
- Toutes les hypothÃ¨ses sont documentÃ©es dans ce fichier